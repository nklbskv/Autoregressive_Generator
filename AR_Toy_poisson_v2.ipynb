{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3233e856",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "debb39d1",
   "metadata": {},
   "source": [
    "# Hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f286ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_CONDITION = False          # <- auf False setzen für unkonditioniert\n",
    "d_model = 128\n",
    "n_head = 4\n",
    "n_layer = 4\n",
    "d_ff = 512\n",
    "dropout = 0.2\n",
    "batch_size = 1024\n",
    "eval_iters = 500\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e31e5bd",
   "metadata": {},
   "source": [
    "# Create dataset\n",
    "\n",
    "Schritte:\n",
    "1. Jeder wert kriegt ein eigenes lambda\n",
    "2. füge den wert n_lambda mal einem string hinzu\n",
    "3. shuffle die sequenz\n",
    "4. erstelle solche strings N mal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "393790bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.arange(1, 5)\n",
    "rates = {1: 6.0, 2: 3.0, 3: 1.5, 4: 0.7}\n",
    "np.random.seed(42)\n",
    "\n",
    "# einzelne sequenz mit poissonverteilten werten innerhalb der sequenz\n",
    "def generate_poisson_string(values):\n",
    "    count = 0\n",
    "    seq = []\n",
    "    for val in values:\n",
    "        count = np.random.poisson(rates[val])\n",
    "        for _ in range(count):\n",
    "            seq.append(val)\n",
    "        count=0\n",
    "    seq = np.array(seq)\n",
    "    np.random.shuffle(seq)\n",
    "    return seq\n",
    "\n",
    "# hänge N sequenzen aneinander und fülle immer bis zur maximalen länge mit 0 auf\n",
    "def generate_dataset(N):\n",
    "    sequences = [generate_poisson_string(values) for _ in range(N)]\n",
    "    max_len = max(len(seq) for seq in sequences)\n",
    "    padded_sequences = np.array([np.pad(seq, (0, max_len - len(seq)), mode='constant', constant_values=0) for seq in sequences])\n",
    "    return padded_sequences\n",
    "\n",
    "data = generate_dataset(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0703062",
   "metadata": {},
   "source": [
    "# Make list of sequences as list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7325db4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_to_lol(dataset):\n",
    "    seqs = []\n",
    "    for row in dataset:\n",
    "        zero_idx = np.argmax(row == 0) if np.any(row == 0) else len(row)\n",
    "        seqs.append(row[:zero_idx])\n",
    "\n",
    "    return seqs\n",
    "\n",
    "seqs = dataset_to_lol(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bbee42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vokabular der Ausgabewerte\n",
    "vals = sorted({v for s in seqs for v in s})\n",
    "\n",
    "# Spezielle Tokens\n",
    "PAD_ID = 0 \n",
    "BOS_ID = 1\n",
    "EOS_ID = 2\n",
    "offset = 3  # Start-ID für echte Werte\n",
    "stoi = {v: i+offset for i,v in enumerate(vals)}\n",
    "itos = {i+offset: v for i,v in enumerate(vals)}\n",
    "\n",
    "vocab_size = offset + len(vals) \n",
    "max_len = max(len(s) for s in seqs)\n",
    "\n",
    "def encode_example(seq):\n",
    "    # Tokenize: BOS + seq + EOS, dann pad\n",
    "    toks = [BOS_ID]\n",
    "    toks += [stoi[v] for v in seq]\n",
    "    toks.append(EOS_ID)\n",
    "    # Ziel ist um 1 nach rechts geschoben\n",
    "    attn_len = len(toks)\n",
    "    pad_needed = ( (max_len + 2) - attn_len )\n",
    "    toks += [PAD_ID] * pad_needed\n",
    "    x = torch.tensor(toks[:-1], dtype=torch.long)  # inputs\n",
    "    y = torch.tensor(toks[1:],  dtype=torch.long)  # targets\n",
    "    return x, y\n",
    "\n",
    "class SeqDataset(Dataset):\n",
    "    def __init__(self, seqs):\n",
    "        self.items = [encode_example(s) for s in seqs]\n",
    "    def __len__(self): return len(self.items)\n",
    "    def __getitem__(self, i): return self.items[i]\n",
    "\n",
    "dataset = SeqDataset(seqs)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))  \n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, drop_last=True, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8ee5a6",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2731d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_head, n_layer, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = nn.Parameter(torch.zeros(1, max_len + 1, d_model))  # +1 für BOS\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, \n",
    "                                                    nhead=n_head, \n",
    "                                                    dim_feedforward=d_ff, \n",
    "                                                    dropout=dropout,\n",
    "                                                    batch_first=True,\n",
    "                                                    activation='relu')\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=n_layer, enable_nested_tensor=False)\n",
    "        self.ff = nn.Linear(d_model, vocab_size)\n",
    "        self.ln = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, targets=None):\n",
    "        B, T = x.size() #Batch, num sequences/time\n",
    "        h = self.token_emb(x) + self.pos_emb[:, :T, :]\n",
    "        causal_mask = torch.triu(torch.ones(T, T, device=x.device), diagonal=1).bool()\n",
    "        key_padding_mask = (x == PAD_ID)\n",
    "        h = self.transformer(h, mask=causal_mask, src_key_padding_mask=key_padding_mask)\n",
    "        h = self.ln(h)\n",
    "        logits = self.ff(h)\n",
    "            \n",
    "        if targets is not None:\n",
    "            B,T,C = logits.size()\n",
    "            logits = logits.view(B*T, C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets, ignore_index=PAD_ID)\n",
    "            return logits, loss\n",
    "        else:\n",
    "            loss=None\n",
    "\n",
    "        return logits, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b7bbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CausalTransformer(vocab_size, d_model, n_head, n_layer, d_ff, dropout).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4afeaed",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "372229fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def estimate_loss(model, train_loader, val_loader, eval_iters=500):\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split, loader in [('train', train_loader), ('val', val_loader)]:\n",
    "        losses = []\n",
    "        for i, (xb, yb) in enumerate(loader):\n",
    "            if eval_iters is not None and i >= eval_iters:\n",
    "                break\n",
    "            else:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                _, loss = model(xb, yb)\n",
    "                losses.append(loss.item())\n",
    "        out[split] = sum(losses) / len(losses) if losses else float('inf')\n",
    "    model.train()\n",
    "    return out\n",
    "            \n",
    "\n",
    "def train_model(model, train_loader, val_loader, epochs, eval_iters=50, lr=1e-3):\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    model.to(device)\n",
    "\n",
    "    #Per epoch losses\n",
    "    train_losses = []\n",
    "    val_losses =  []\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        metrics = estimate_loss(model, train_loader, val_loader, eval_iters=eval_iters)\n",
    "        val_losses.append(metrics['val'])\n",
    "\n",
    "        if epoch == epochs: break\n",
    "    \n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for x, y in tqdm(train_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            _, loss = model(x, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73854744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b554b7f522b416987193a8e8824b509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7377af7f32f4823bb8500851e443492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "365ea16525ee44c38ff99e4ff8b35be9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4c0d27932994a6b9d63d1de8fb1a67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53eeb1dc609640658f579a85f6f88991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69c84672806140179d5a7ee97f0ef9a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/781 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trained_model = train_model(model, train_loader, val_loader, epochs=5, eval_iters=eval_iters, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f954a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_losses, val_losses = trained_model\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "737b56d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317a0ca91e3948cd93fee613c604a33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating sequences:   0%|          | 0/98 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 98: Showing details for sequences [50000] ===\n",
      "\n",
      "Step 1:\n",
      "Top probabilities:\n",
      "  γ: 0.541\n",
      "  e: 0.265\n",
      "  p: 0.135\n",
      "  P: 0.059\n",
      "  EOS: 0.000\n",
      "Selected: p\n",
      "Current sequence: BOSp\n",
      "\n",
      "Step 2:\n",
      "Top probabilities:\n",
      "  γ: 0.534\n",
      "  e: 0.267\n",
      "  p: 0.138\n",
      "  P: 0.061\n",
      "  EOS: 0.000\n",
      "Selected: e\n",
      "Current sequence: BOSpe\n",
      "\n",
      "Step 3:\n",
      "Top probabilities:\n",
      "  γ: 0.532\n",
      "  e: 0.266\n",
      "  p: 0.138\n",
      "  P: 0.063\n",
      "  EOS: 0.001\n",
      "Selected: P\n",
      "Current sequence: BOSpeP\n",
      "\n",
      "Step 4:\n",
      "Top probabilities:\n",
      "  γ: 0.528\n",
      "  e: 0.267\n",
      "  p: 0.135\n",
      "  P: 0.065\n",
      "  EOS: 0.005\n",
      "Selected: γ\n",
      "Current sequence: BOSpePγ\n",
      "\n",
      "Step 5:\n",
      "Top probabilities:\n",
      "  γ: 0.529\n",
      "  e: 0.265\n",
      "  p: 0.132\n",
      "  P: 0.064\n",
      "  EOS: 0.010\n",
      "Selected: e\n",
      "Current sequence: BOSpePγe\n",
      "\n",
      "Step 6:\n",
      "Top probabilities:\n",
      "  γ: 0.520\n",
      "  e: 0.264\n",
      "  p: 0.129\n",
      "  P: 0.063\n",
      "  EOS: 0.023\n",
      "Selected: e\n",
      "Current sequence: BOSpePγee\n",
      "\n",
      "Step 7:\n",
      "Top probabilities:\n",
      "  γ: 0.513\n",
      "  e: 0.259\n",
      "  p: 0.126\n",
      "  P: 0.062\n",
      "  EOS: 0.040\n",
      "Selected: e\n",
      "Current sequence: BOSpePγeee\n",
      "\n",
      "Step 8:\n",
      "Top probabilities:\n",
      "  γ: 0.504\n",
      "  e: 0.253\n",
      "  p: 0.123\n",
      "  P: 0.061\n",
      "  EOS: 0.060\n",
      "Selected: γ\n",
      "Current sequence: BOSpePγeeeγ\n",
      "\n",
      "Step 9:\n",
      "Top probabilities:\n",
      "  γ: 0.489\n",
      "  e: 0.241\n",
      "  p: 0.118\n",
      "  EOS: 0.092\n",
      "  P: 0.060\n",
      "Selected: γ\n",
      "Current sequence: BOSpePγeeeγγ\n",
      "\n",
      "Step 10:\n",
      "Top probabilities:\n",
      "  γ: 0.472\n",
      "  e: 0.233\n",
      "  EOS: 0.123\n",
      "  p: 0.114\n",
      "  P: 0.058\n",
      "Selected: p\n",
      "Current sequence: BOSpePγeeeγγp\n",
      "\n",
      "*** FINAL STEP 11 (EOS generated) ***\n",
      "Top probabilities:\n",
      "  γ: 0.450\n",
      "  e: 0.225\n",
      "  EOS: 0.162\n",
      "  p: 0.109\n",
      "  P: 0.054\n",
      "Selected: EOS (sequence will end)\n",
      "Current sequence: BOSpePγeeeγγpEOS\n",
      "\n",
      "All sequences in batch finished at step 23\n",
      "\n",
      "Final sequence 50000:\n",
      "BOSpePγeeeγγpEOS\n",
      "Total length: 10 tokens + EOS\n",
      "Particle composition:\n",
      "  p: 2x\n",
      "  e: 4x\n",
      "  P: 1x\n",
      "  γ: 3x\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "@torch.no_grad()\n",
    "def sample_particle_sequences_parallel(model, n_seqs=50000, temperature=1.0, show_last_n=1, batch_size=512):\n",
    "    # Teilchen-Dictionary\n",
    "    particle_map = {1: 'γ', 2: 'e', 3: 'p', 4: 'P'}\n",
    "    token_map = {PAD_ID: \"PAD\", BOS_ID: \"BOS\", EOS_ID: \"EOS\"}\n",
    "    \n",
    "    model.eval()\n",
    "    all_sequences = []\n",
    "\n",
    "    # Generiere in Batches für GPU-Effizienz\n",
    "    for batch_start in tqdm(range(0, n_seqs, batch_size), desc=\"Generating sequences\"):\n",
    "        current_batch_size = min(batch_size, n_seqs - batch_start)\n",
    "        \n",
    "        # Batch von BOS-Tokens als Start\n",
    "        idx = torch.tensor([[BOS_ID]] * current_batch_size, device=device)  # (batch_size, 1)\n",
    "        sequences = [[] for _ in range(current_batch_size)]  # Für jeden Batch-Eintrag\n",
    "        finished = torch.zeros(current_batch_size, dtype=torch.bool, device=device)\n",
    "        \n",
    "        # Detaillierte Ausgabe für bestimmte Sequenzen\n",
    "        show_details_for = []\n",
    "        for i in range(current_batch_size):\n",
    "            global_idx = batch_start + i\n",
    "            if global_idx >= (n_seqs - show_last_n):\n",
    "                show_details_for.append(i)\n",
    "        \n",
    "        if show_details_for:\n",
    "            print(f\"\\n=== Batch {batch_start//batch_size + 1}: Showing details for sequences {[batch_start + i + 1 for i in show_details_for]} ===\")\n",
    "        \n",
    "        for step in range(max_len):\n",
    "            # Parallelisierter Forward-Pass für den ganzen Batch\n",
    "            logits, _ = model(idx)  # KORREKTUR: Tupel unpacking\n",
    "            logits = logits[:, -1, :] / temperature  # (batch_size, vocab_size)\n",
    "            \n",
    "            # Parallelisiertes Sampling\n",
    "            probs = F.softmax(logits, dim=-1)  # (batch_size, vocab_size)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (batch_size, 1)\n",
    "            \n",
    "            # Überprüfe, ob für Debug-Sequenzen EOS generiert wurde\n",
    "            show_eos_step = False\n",
    "            if show_details_for:\n",
    "                for detail_idx in show_details_for:\n",
    "                    if not finished[detail_idx] and idx_next[detail_idx].item() == EOS_ID:\n",
    "                        show_eos_step = True\n",
    "                        break\n",
    "            \n",
    "            # Zeige Details für ausgewählte Sequenzen\n",
    "            # Erweitert: Zeige auch EOS-Step (auch wenn > 10)\n",
    "            if show_details_for and (step < 10 or show_eos_step):\n",
    "                for detail_idx in show_details_for:\n",
    "                    if not finished[detail_idx]:\n",
    "                        seq_num = batch_start + detail_idx + 1\n",
    "                        \n",
    "                        # Spezielle Markierung für EOS-Step\n",
    "                        if idx_next[detail_idx].item() == EOS_ID:\n",
    "                            print(f\"\\n*** FINAL STEP {step + 1} (EOS generated) ***\")\n",
    "                        elif step < 10:\n",
    "                            print(f\"\\nStep {step + 1}:\")\n",
    "                        else:\n",
    "                            continue  # Skip andere Steps > 10 die kein EOS sind\n",
    "                        \n",
    "                        # Top-5 Wahrscheinlichkeiten für diese Sequenz\n",
    "                        seq_probs = probs[detail_idx]\n",
    "                        top_probs, top_indices = torch.topk(seq_probs, k=5)\n",
    "                        \n",
    "                        print(\"Top probabilities:\")\n",
    "                        for p, token_id in zip(top_probs.cpu().numpy(), top_indices.cpu().numpy()):\n",
    "                            if token_id in itos:\n",
    "                                particle_id = itos[token_id]\n",
    "                                particle_char = particle_map.get(particle_id, f\"?{particle_id}\")\n",
    "                                token_str = f\"{particle_char}\"\n",
    "                            else:\n",
    "                                token_str = token_map.get(token_id, f\"Token {token_id}\")\n",
    "                            print(f\"  {token_str}: {p:.3f}\")\n",
    "                        \n",
    "                        # Gewähltes Token\n",
    "                        chosen_id = idx_next[detail_idx].item()\n",
    "                        if chosen_id in itos:\n",
    "                            particle_id = itos[chosen_id]\n",
    "                            particle_char = particle_map.get(particle_id, f\"?{particle_id}\")\n",
    "                            print(f\"Selected: {particle_char}\")\n",
    "                        elif chosen_id == EOS_ID:\n",
    "                            print(f\"Selected: EOS (sequence will end)\")\n",
    "                        else:\n",
    "                            print(f\"Selected: {token_map.get(chosen_id, f'Token {chosen_id}')}\")\n",
    "                        \n",
    "                        # Aktuelle Sequenz\n",
    "                        current_seq = [\"BOS\"]\n",
    "                        for tok_id in sequences[detail_idx]:\n",
    "                            if tok_id in itos:\n",
    "                                particle_id = itos[tok_id]\n",
    "                                particle_char = particle_map.get(particle_id, f\"?{particle_id}\")\n",
    "                                current_seq.append(particle_char)\n",
    "                            elif tok_id == EOS_ID:\n",
    "                                current_seq.append(\"EOS\")\n",
    "                                break\n",
    "                            else:\n",
    "                                current_seq.append(\"?\")\n",
    "                        \n",
    "                        # Füge neues Token hinzu\n",
    "                        if chosen_id in itos:\n",
    "                            particle_id = itos[chosen_id]\n",
    "                            particle_char = particle_map.get(particle_id, f\"?{particle_id}\")\n",
    "                            current_seq.append(particle_char)\n",
    "                        elif chosen_id == EOS_ID:\n",
    "                            current_seq.append(\"EOS\")\n",
    "                        \n",
    "                        current_seq_str = \"\".join(current_seq)\n",
    "                        print(f\"Current sequence: {current_seq_str}\")\n",
    "            \n",
    "            # Info über übersprungene Schritte\n",
    "            elif show_details_for and step == 10:\n",
    "                for detail_idx in show_details_for:\n",
    "                    if not finished[detail_idx]:\n",
    "                        print(f\"\\n... continuing generation silently until EOS or max_len ({max_len}) ...\")\n",
    "                        break\n",
    "            \n",
    "            # Update für alle Sequenzen im Batch\n",
    "            for i in range(current_batch_size):\n",
    "                if not finished[i]:\n",
    "                    token_id = idx_next[i].item()\n",
    "                    sequences[i].append(token_id)\n",
    "                    \n",
    "                    # Markiere als beendet wenn EOS\n",
    "                    if token_id == EOS_ID:\n",
    "                        finished[i] = True\n",
    "            \n",
    "            # Erweitere idx für alle Sequenzen\n",
    "            idx = torch.cat([idx, idx_next], dim=1)  # (batch_size, seq_len+1)\n",
    "            \n",
    "            # Stoppe wenn alle Sequenzen beendet sind\n",
    "            if finished.all():\n",
    "                if show_details_for:\n",
    "                    print(f\"\\nAll sequences in batch finished at step {step + 1}\")\n",
    "                break\n",
    "        \n",
    "        # Sammle Sequenzen aus diesem Batch\n",
    "        for i, seq in enumerate(sequences):\n",
    "            full_seq = [BOS_ID] + seq  # BOS + generierte Tokens\n",
    "            all_sequences.append(full_seq)\n",
    "        \n",
    "        # Zeige finale Sequenzen für Details\n",
    "        if show_details_for:\n",
    "            for detail_idx in show_details_for:\n",
    "                seq_num = batch_start + detail_idx + 1\n",
    "                seq = sequences[detail_idx]\n",
    "                \n",
    "                print(f\"\\nFinal sequence {seq_num}:\")\n",
    "                final_seq = [\"BOS\"]\n",
    "                particle_counts = {}\n",
    "                \n",
    "                for token_id in seq:\n",
    "                    if token_id in itos:\n",
    "                        particle_id = itos[token_id]\n",
    "                        particle_char = particle_map.get(particle_id, f\"?{particle_id}\")\n",
    "                        final_seq.append(particle_char)\n",
    "                        particle_counts[particle_char] = particle_counts.get(particle_char, 0) + 1\n",
    "                    elif token_id == EOS_ID:\n",
    "                        final_seq.append(\"EOS\")\n",
    "                        break\n",
    "                    else:\n",
    "                        final_seq.append(\"?\")\n",
    "                \n",
    "                sequence_str = \"\".join(final_seq)\n",
    "                print(f\"{sequence_str}\")\n",
    "                print(f\"Total length: {len([t for t in seq if t != EOS_ID])} tokens + EOS\")\n",
    "                \n",
    "                if particle_counts:\n",
    "                    print(\"Particle composition:\")\n",
    "                    for particle, count in particle_counts.items():\n",
    "                        print(f\"  {particle}: {count}x\")\n",
    "            print(\"-\" * 50)\n",
    "\n",
    "    # Konvertiere zu finalen Sequenzen (ohne BOS, EOS, PAD)\n",
    "    actual_seqs = []\n",
    "    for seq in all_sequences:\n",
    "        valid_tokens = [itos[t] for t in seq if t not in [BOS_ID, EOS_ID, PAD_ID] and t in itos]\n",
    "        actual_seqs.append(valid_tokens)\n",
    "\n",
    "    model.train()\n",
    "    return actual_seqs\n",
    "\n",
    "# Verwende die angepasste Version\n",
    "actual_seqs = sample_particle_sequences_parallel(\n",
    "    model, \n",
    "    n_seqs=50000, \n",
    "    show_last_n=1, \n",
    "    batch_size=512,\n",
    "    temperature=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c20306",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
